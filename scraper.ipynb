{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vf5yx_nJNNwm"
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install pinecone-client\n",
    "!pip install openai\n",
    "!pip install tiktoken\n",
    "!pip install nest_asyncio\n",
    "!pip install -qU langchain-pinecone pinecone-notebooks\n",
    "!pip install -qU langchain-openai\n",
    "!pip install -qU langchain_community beautifulsoup4\n",
    "!pip install -qU langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmbmOHfbNPVc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"INSERT_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHlQlvn_NQYx"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key=\"INSERT_PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3uQMBVPNRhx",
    "outputId": "2583ec74-bde4-45c7-c2a1-bfa5729e160b"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_links_from_sitemaps(sitemap_urls):\n",
    "    unique_links = set()  # Use a set to automatically handle duplicates\n",
    "\n",
    "    for sitemap_url in sitemap_urls:\n",
    "        try:\n",
    "            # Fetch the sitemap XML\n",
    "            response = requests.get(sitemap_url)\n",
    "            response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "\n",
    "            # Parse the XML content\n",
    "            root = ET.fromstring(response.content)\n",
    "\n",
    "            # Extract all URLs\n",
    "            namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "            urls = [url.find('ns:loc', namespace).text for url in root.findall('ns:url', namespace)]\n",
    "\n",
    "            # Add URLs to the set (removes duplicates automatically)\n",
    "            unique_links.update(urls)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {sitemap_url}: {e}\")\n",
    "\n",
    "    return list(unique_links)  # Convert set back to a list for output\n",
    "\n",
    "# Academic Index\n",
    "academic_sitemaps = [\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-5248b7443/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-4978d3772/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-be9b5792e/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-92539e5b7/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-a2ae93abb/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-49abdde73/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-be9b5797e/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-ee758a7aa/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-92539eb87/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-4978d3e92/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-92539eb77/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-8e958a7b4/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-be9b5723e/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-92539eb87/sitemap.xml?view=1\"\n",
    "]\n",
    "academic_urls = get_links_from_sitemaps(academic_sitemaps)\n",
    "\n",
    "# Health & Safety Index\n",
    "health_and_safety_sitemaps = [\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-3db8e5e42/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-4978d3d8b/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-ee758a855/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-3db8e5ee2/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-da3b72758/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-2d58eb2a5/sitemap.xml?view=1\"\n",
    "]\n",
    "health_and_safety_urls = get_links_from_sitemaps(health_and_safety_sitemaps)\n",
    "\n",
    "# Services Index\n",
    "services_sitemaps = [\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-92539ebaa/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-3db8e5a98/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-74abe235d/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-a2ae93b53/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-be9b57254/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-3db8e5ae8/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-4978d3ed7/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-ee758a983/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-92539eb3a/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-3db8e5a88/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-a2ae93be3/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-da3b72e8d/sitemap.xml?view=1\"\n",
    "]\n",
    "services_urls = get_links_from_sitemaps(services_sitemaps)\n",
    "\n",
    "# Technology Index\n",
    "technology_sitemaps = [\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-4978d3579/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-74abe2537/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-ee758abd8/sitemap.xml?view=1\",\n",
    "    \"https://www.xml-sitemaps.com/download/www.scu.edu-da3b725bb/sitemap.xml?view=1\"\n",
    "]\n",
    "technology_urls = get_links_from_sitemaps(technology_sitemaps)\n",
    "\n",
    "general_urls = academic_urls + health_and_safety_urls + services_urls + technology_urls\n",
    "\n",
    "# technology-index, academic-index, health-and-safety-index, services-index, general-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixes a bug with asyncio and jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Arrange\n",
    "fail_page  = [\"https://www.scu.edu/failure\"]\n",
    "\n",
    "# Create a WebBaseLoader to scrape the not found page for scu.edu\n",
    "loader = WebBaseLoader(fail_page)\n",
    "loader.requests_per_second = 1\n",
    "fail_case = loader.aload()\n",
    "\n",
    "# Create a WebBaseLoader to scrape the provided URLs\n",
    "loader = WebBaseLoader(general_urls)\n",
    "loader.requests_per_second = 1\n",
    "docs = loader.aload()\n",
    "\n",
    "# Assert\n",
    "for doc in docs[:]:\n",
    "    # If any of the scraped urls re-dircted to the not found page\n",
    "    if doc.page_content == fail_case[0].page_content or len(doc.page_content) == 0:\n",
    "        # Output the url\n",
    "        print(doc.metadata[\"source\"])\n",
    "        docs.remove(doc)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szh47uCQNS-7"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1200,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "\n",
    "docs_chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "print(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjZxwGOsNUIo"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MspxdmDTNWqx"
   },
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import ServerlessSpec\n",
    "import time\n",
    "\n",
    "\n",
    "index_name = \"general-index\"  # change if desired\n",
    "\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "\n",
    "docsearch = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-54lv8baNX8r"
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(docs_chunks))]\n",
    "\n",
    "\n",
    "docsearch.add_documents(documents=docs_chunks, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH86uDHjNjSF"
   },
   "source": [
    "FullStack Application Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKyzoe1qM6zj"
   },
   "outputs": [],
   "source": [
    "# Needs to be run only once as a setup\n",
    "import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"INSERT_OPENAI_API_KEY\"\n",
    "\n",
    "from pinecone import Pinecone\n",
    "# pc = Pinecone(api_key=\"INSERT_PINECONE_API_KEY\")\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "llm=OpenAI()\n",
    "\n",
    "def split_https(entries):\n",
    "  result = []\n",
    "  for entry in entries:\n",
    "      parts = entry.split('https:')\n",
    "      for part in parts:\n",
    "          if part:\n",
    "              result.append('https:' + part)\n",
    "  return result\n",
    "\n",
    "def create_chain(vectorStore):\n",
    "    system_prompt = (\n",
    "        \"You are an AI assistant designed to help students at Santa Clara University (SCU) navigate university resources, based on their personal needs.\"\n",
    "        \"Be friendly, and approachable.\"\n",
    "        \"Do NOT attempt to guess or complete unfinished questions.\"\n",
    "        \"If what is being asked of you appears to be incomplete, do not complete it, and instead respond saying it looks incomplete.\"\n",
    "        \"If you cannot find the answer in the context, say you cannot find it, rather than answer it.\"\n",
    "        \"Answer based on this context: {context}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    retriever = vectorStore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    retrival_prompt = (\n",
    "        \"Given a chat history and the latest user question which might reference the chat history above,\"\n",
    "        \"formulate a standalone question which can be understood without the chat history.\"\n",
    "        \"Do NOT answer the question or attempt to the complete it if it looks incomplete.\"\n",
    "        \"Just reformulate it, if it looks complete, and otherwise return it as is.\"\n",
    "    )\n",
    "\n",
    "    retriever_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", retrival_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        prompt=retriever_prompt\n",
    "    )\n",
    "\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        history_aware_retriever,\n",
    "        chain\n",
    "    )\n",
    "\n",
    "    return retrieval_chain\n",
    "\n",
    "'''client = OpenAI()\n",
    "prompt = PromptTemplate.from_template(\"Evaluate each user input to determine if it is complete or incomplete. If the input is an open-ended, short, or vague question (such as 'Where?' or 'What is?'), mark it as incomplete unless the recent chat history provides clear context for the question. If the input references specific information (like 'Where is the park?'), consider it complete. Only use chat history to interpret short questions when they logically relate to previous messages. Here is the chat history: {chat_history} Here is the user input: {input}\")\n",
    "complete_chain = prompt | client'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGsjy0IhA9aF"
   },
   "outputs": [],
   "source": [
    "# Run To Select/Swap Database\n",
    "\n",
    "indicies = [\"general-index\", \"academic-index\", \"health-and-safety-index\", \"services-index\", \"technology-index\"]\n",
    "\n",
    "select = 5\n",
    "while select != 0 and select != 1 and select != 2 and select != 3 and select != 4:\n",
    "  print(\"[0] General\")\n",
    "  print(\"[1] Academic\")\n",
    "  print(\"[2] Health & Safety\")\n",
    "  print(\"[3] Services\")\n",
    "  print(\"[4] Technology\")\n",
    "  select = int(input(\"Which do you need help with?\"))\n",
    "  index_name = indicies[select]\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "docsearch = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "# Run For User To Interact With Chatbot\n",
    "chat_history = []\n",
    "chain = create_chain(docsearch)\n",
    "while True:\n",
    "  query = input(\"What do you need help with?\")\n",
    "  if query.lower() == \"exit\":\n",
    "    break\n",
    "  '''output = complete_chain.invoke({\n",
    "        \"input\": query,\n",
    "        \"chat_history\": chat_history\n",
    "  })\n",
    "  print(output)\n",
    "  if \"incomplete\" == output.lower():\n",
    "    print(\"Please be more specific.\")\n",
    "  else:'''\n",
    "  result = chain.invoke({\n",
    "        \"chat_history\": chat_history,\n",
    "        \"input\": query,\n",
    "  })\n",
    "  retrival_question = result[\"answer\"].split(\":\", 1)[0]\n",
    "  output = result[\"answer\"].split(\":\", 1)[1]\n",
    "  sources = [doc.metadata[\"source\"] for doc in result[\"context\"]]\n",
    "  sources = set(split_https(sources))\n",
    "  chat_history.append(HumanMessage(content=query))\n",
    "  chat_history.append(AIMessage(content=output))\n",
    "  print(output)\n",
    "  print(\"Sources:\")\n",
    "  for source in sources:\n",
    "    print(source)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "webapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
